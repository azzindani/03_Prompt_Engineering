{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/00-llm-fine-tune-peft-v1-8640645a-48d1-4ab4-9544-e0101eabb0ed.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20241101/auto/storage/goog4_request&X-Goog-Date=20241101T092253Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=0d6f408ecb309cbcd081e92a7e45eaa76ae38073acfabe7de338f38021bb9de9c13868853c33f34831bc749caf833c0eae4452632ce05d01aed60b8e202481abdf3f85fb2124e578a87c289913e4386e67eec1b8510ebbf45aa8e8ab4e0aea1a6ee13fff5d5f5544c374a2a19367298840061b1abc594452b913b29c0dcbf0677b5540c1ee5825d4f8eeb1e6bf71bd6eba6ccbcd61f2f66d425a9704cacc11e988f36fe47f76770a22c523699c43670e07f57608c8325cc285bbf7553ef98fececc0dff4f2279f7e198d7c3ea516df946b1ff376b45045a4611794f28eb96af6a262d756ddfdcc74e3e5bff83708e05ef6d2cbf1646d86ccadc850e30567f7f8","timestamp":1730693187949}]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"c05760c966c84d548d89a4a4549479bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_afecb1fe723940a196412f460073c6e3","IPY_MODEL_51a3b74552984703bedcc773eb3f6222","IPY_MODEL_2e8773bd96e24ad6911b102fd0be1722"],"layout":"IPY_MODEL_14152e2ae69a4378921eb9212ad11ac3"}},"afecb1fe723940a196412f460073c6e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6b7b2b12542447c804bb2e32aefaa67","placeholder":"​","style":"IPY_MODEL_e19d7a430d4f45b08b981aa35f0ff871","value":"config.json: 100%"}},"51a3b74552984703bedcc773eb3f6222":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d19469c8fc474c8f8329f380d6c4fa15","max":928,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb59838449ea44209b3a1dec302ee9a7","value":928}},"2e8773bd96e24ad6911b102fd0be1722":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a5111d532894f89b76374c07e8c4d39","placeholder":"​","style":"IPY_MODEL_95795695644e48f8b740a7a1743e96c7","value":" 928/928 [00:00&lt;00:00, 26.0kB/s]"}},"14152e2ae69a4378921eb9212ad11ac3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6b7b2b12542447c804bb2e32aefaa67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e19d7a430d4f45b08b981aa35f0ff871":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d19469c8fc474c8f8329f380d6c4fa15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb59838449ea44209b3a1dec302ee9a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a5111d532894f89b76374c07e8c4d39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95795695644e48f8b740a7a1743e96c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3773fae71bf647aa81c8f3a5b91b6405":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc77cb8b178d445396939b272f08e81d","IPY_MODEL_80d1c465546d4fd79d07d1b914ee85f3","IPY_MODEL_d5f0eb7210b0421ba2795063457ea558"],"layout":"IPY_MODEL_483e6ce056fc4de682f3e198e394a9cc"}},"fc77cb8b178d445396939b272f08e81d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e0e68b59a804dea96da0f3af8887d90","placeholder":"​","style":"IPY_MODEL_3ffbaf008b824f76b16a3bc76f863dd9","value":"model.safetensors:   6%"}},"80d1c465546d4fd79d07d1b914ee85f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_96044d3717a34651b96e210fd423308b","max":6425529112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29c938c0b79942c8a1ce54a1368975b6","value":356515840}},"d5f0eb7210b0421ba2795063457ea558":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_167842de375d4d4eb1c795b8e193c069","placeholder":"​","style":"IPY_MODEL_227c4d9a5a5b47b1a347396ab14a1a7c","value":" 357M/6.43G [00:08&lt;02:20, 43.1MB/s]"}},"483e6ce056fc4de682f3e198e394a9cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e0e68b59a804dea96da0f3af8887d90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ffbaf008b824f76b16a3bc76f863dd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96044d3717a34651b96e210fd423308b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29c938c0b79942c8a1ce54a1368975b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"167842de375d4d4eb1c795b8e193c069":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"227c4d9a5a5b47b1a347396ab14a1a7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 00 Import Modules","metadata":{"id":"iNW_MCROx_hX"}},{"cell_type":"code","source":"#!pip install --upgrade transformers\n!pip install -q peft\n!pip install -U -q bitsandbytes\n!pip install -q datasets\n!pip install -q trl","metadata":{"id":"0-QxfiDVyT74","trusted":true,"outputId":"69d52dc0-ca27-4fd1-81c4-bc2f70300670","executionInfo":{"status":"ok","timestamp":1731567442462,"user_tz":-420,"elapsed":23144,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-11-15T03:09:12.008675Z","iopub.execute_input":"2024-11-15T03:09:12.009050Z","iopub.status.idle":"2024-11-15T03:09:58.728654Z","shell.execute_reply.started":"2024-11-15T03:09:12.009014Z","shell.execute_reply":"2024-11-15T03:09:58.727208Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport pathlib\nimport torch\nimport numpy as np\n\nfrom datetime import datetime\nfrom datasets import load_dataset\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom trl import SFTTrainer\n\nfrom transformers import (\n  AutoTokenizer,\n  AutoModelForCausalLM,\n  AutoModelForSeq2SeqLM,\n  AutoModel,\n  AutoModelForSequenceClassification,\n  DataCollatorForLanguageModeling,\n  Trainer,\n  TrainingArguments,\n  pipeline,\n  TextDataset,\n  EvalPrediction,\n  DataCollatorWithPadding,\n  GenerationConfig,\n  BitsAndBytesConfig,\n  DataCollatorForSeq2Seq,\n  TextStreamer\n)\n\nfrom peft import (\n  LoraConfig,\n  PeftModelForSequenceClassification,\n  PeftModel,\n  TaskType,\n  AutoPeftModelForSequenceClassification,\n  get_peft_model,\n  prepare_model_for_kbit_training\n)\n\nif torch.cuda.is_available():\n  print(\"GPU is available!\")\nelse:\n  print(\"GPU is not available.\")","metadata":{"id":"TIgNx9Orx0It","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":36099,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"248c8f10-5eae-49a5-ba03-c6c30698404f","execution":{"iopub.status.busy":"2024-11-15T03:09:58.731355Z","iopub.execute_input":"2024-11-15T03:09:58.731789Z","iopub.status.idle":"2024-11-15T03:10:07.218680Z","shell.execute_reply.started":"2024-11-15T03:09:58.731736Z","shell.execute_reply":"2024-11-15T03:10:07.217720Z"}},"outputs":[{"name":"stdout","text":"GPU is available!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"id":"i-nwkyTDybqY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":6,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"f7789872-8053-4e26-a665-0c4f94689529","execution":{"iopub.status.busy":"2024-11-15T03:10:07.219938Z","iopub.execute_input":"2024-11-15T03:10:07.220275Z","iopub.status.idle":"2024-11-15T03:10:07.227759Z","shell.execute_reply.started":"2024-11-15T03:10:07.220240Z","shell.execute_reply":"2024-11-15T03:10:07.226848Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## 01 Import Model","metadata":{"id":"grIeJpUdyX0Y"}},{"cell_type":"code","source":"#url = 'https://huggingface.co/Qwen/Qwen2.5-0.5B'\n#model_name = url.split('.co/')[-1]\n\nmodel_name = 'unsloth/SmolLM2-1.7B-Instruct'","metadata":{"id":"14Lkvw4cyZkY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":4,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-11-15T03:10:07.230607Z","iopub.execute_input":"2024-11-15T03:10:07.231010Z","iopub.status.idle":"2024-11-15T03:10:07.238760Z","shell.execute_reply.started":"2024-11-15T03:10:07.230963Z","shell.execute_reply":"2024-11-15T03:10:07.237869Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n  load_in_4bit = True,\n  bnb_4bit_quant_type = 'nf4',\n  bnb_4bit_compute_dtype = torch.float16,\n  bnb_4bit_use_double_quant = True,\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n  model_name,\n  quantization_config = bnb_config,\n  trust_remote_code = True\n).to(device) #'''","metadata":{"id":"GlskFscYyeco","trusted":true,"outputId":"f13e208f-69a8-4f9a-a814-0e87d3dda84f","execution":{"iopub.status.busy":"2024-11-15T03:10:07.239839Z","iopub.execute_input":"2024-11-15T03:10:07.240164Z","iopub.status.idle":"2024-11-15T03:10:14.165684Z","shell.execute_reply.started":"2024-11-15T03:10:07.240126Z","shell.execute_reply":"2024-11-15T03:10:14.164879Z"}},"outputs":[{"name":"stderr","text":"`low_cpu_mem_usage` was None, now default to True since model is quantized.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"'''model = AutoModelForCausalLM.from_pretrained(\n  model_name,\n  torch_dtype = torch.float16,\n  trust_remote_code = True\n).to(device) #'''","metadata":{"id":"dQ3WZpjeyfGg","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:10:14.166774Z","iopub.execute_input":"2024-11-15T03:10:14.167065Z","iopub.status.idle":"2024-11-15T03:10:14.173594Z","shell.execute_reply.started":"2024-11-15T03:10:14.167021Z","shell.execute_reply":"2024-11-15T03:10:14.172586Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'model = AutoModelForCausalLM.from_pretrained(\\n  model_name,\\n  torch_dtype = torch.float16,\\n  trust_remote_code = True\\n).to(device) #'"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"model","metadata":{"id":"HIYgZ1xF1qsl","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:10:14.174761Z","iopub.execute_input":"2024-11-15T03:10:14.175079Z","iopub.status.idle":"2024-11-15T03:10:14.186780Z","shell.execute_reply.started":"2024-11-15T03:10:14.175028Z","shell.execute_reply":"2024-11-15T03:10:14.185956Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(49153, 2048, padding_idx=49152)\n    (layers): ModuleList(\n      (0-23): 24 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n          (k_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n          (v_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n          (up_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n          (down_proj): Linear4bit(in_features=8192, out_features=2048, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=2048, out_features=49153, bias=False)\n)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"j6d6uYBfzCC4","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:10:14.187898Z","iopub.execute_input":"2024-11-15T03:10:14.188216Z","iopub.status.idle":"2024-11-15T03:10:14.200980Z","shell.execute_reply.started":"2024-11-15T03:10:14.188182Z","shell.execute_reply":"2024-11-15T03:10:14.200080Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 906072064\nTrainable parameters : 100765696\nTrainable percentage: 11.12%\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## 02 Import Tokenizer","metadata":{"id":"MU_19rT5zEIZ"}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\n#tokenizer","metadata":{"id":"lpB5JUjSzGtJ","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:10:14.202007Z","iopub.execute_input":"2024-11-15T03:10:14.202325Z","iopub.status.idle":"2024-11-15T03:10:14.455582Z","shell.execute_reply.started":"2024-11-15T03:10:14.202293Z","shell.execute_reply":"2024-11-15T03:10:14.454769Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## 03 Import Dataset","metadata":{"id":"3QJUqcUVzNoJ"}},{"cell_type":"code","source":"#url = 'https://huggingface.co/datasets/KingNish/reasoning-base-20k'\n#dataset_name = url.split('datasets/')[-1]\n\ndataset_name = 'mlabonne/FineTome-100k'","metadata":{"id":"U01UXJdLzPXS","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:10:14.458973Z","iopub.execute_input":"2024-11-15T03:10:14.459282Z","iopub.status.idle":"2024-11-15T03:10:14.463761Z","shell.execute_reply.started":"2024-11-15T03:10:14.459250Z","shell.execute_reply":"2024-11-15T03:10:14.462586Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"max_length = 1024","metadata":{"id":"ZGIUyIDhNJC2","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:10:14.464893Z","iopub.execute_input":"2024-11-15T03:10:14.465204Z","iopub.status.idle":"2024-11-15T03:10:14.474358Z","shell.execute_reply.started":"2024-11-15T03:10:14.465171Z","shell.execute_reply":"2024-11-15T03:10:14.473448Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"dataset = load_dataset(dataset_name, split = 'train')\ndataset","metadata":{"id":"0ucM3l_FzUkp","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:10:14.475436Z","iopub.execute_input":"2024-11-15T03:10:14.475864Z","iopub.status.idle":"2024-11-15T03:10:20.523066Z","shell.execute_reply.started":"2024-11-15T03:10:14.475829Z","shell.execute_reply":"2024-11-15T03:10:20.522069Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['conversations', 'source', 'score'],\n    num_rows: 100000\n})"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"dataset.select(range(5)).to_pandas().head()","metadata":{"id":"FLRSMhJDzY5Z","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:10:20.524288Z","iopub.execute_input":"2024-11-15T03:10:20.524689Z","iopub.status.idle":"2024-11-15T03:10:20.569558Z","shell.execute_reply.started":"2024-11-15T03:10:20.524650Z","shell.execute_reply":"2024-11-15T03:10:20.568666Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                       conversations  \\\n0  [{'from': 'human', 'value': 'Explain what bool...   \n1  [{'from': 'human', 'value': 'Explain how recur...   \n2  [{'from': 'human', 'value': 'Explain what bool...   \n3  [{'from': 'human', 'value': 'Explain the conce...   \n4  [{'from': 'human', 'value': 'Print the reverse...   \n\n                     source     score  \n0  infini-instruct-top-500k  5.212621  \n1  infini-instruct-top-500k  5.157649  \n2  infini-instruct-top-500k  5.147540  \n3  infini-instruct-top-500k  5.053656  \n4  infini-instruct-top-500k  5.045648  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>conversations</th>\n      <th>source</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[{'from': 'human', 'value': 'Explain what bool...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.212621</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[{'from': 'human', 'value': 'Explain how recur...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.157649</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[{'from': 'human', 'value': 'Explain what bool...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.147540</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[{'from': 'human', 'value': 'Explain the conce...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.053656</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[{'from': 'human', 'value': 'Print the reverse...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.045648</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"dataset[0]","metadata":{"id":"3exPEy0JdLyI","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:10:20.570647Z","iopub.execute_input":"2024-11-15T03:10:20.570952Z","iopub.status.idle":"2024-11-15T03:10:20.579980Z","shell.execute_reply.started":"2024-11-15T03:10:20.570919Z","shell.execute_reply":"2024-11-15T03:10:20.579019Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'conversations': [{'from': 'human',\n   'value': 'Explain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \\n\\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\\n\\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.'},\n  {'from': 'gpt',\n   'value': 'Boolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\\n\\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\\n\\n```python\\nx = 5\\nresult = not (x > 10)  # This expression evaluates to True\\n```\\n\\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\\n\\n```python\\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\\n```\\n\\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\\n\\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\\n\\n```python\\nif x != 0 and (y / x) > 10:\\n    # Perform some operation\\n```\\n\\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here\\'s an example in pseudocode:\\n\\n```\\nif x != 0 {\\n    if (y / x) > 10 {\\n        // Perform some operation\\n    }\\n}\\n```\\n\\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\\n\\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\\n\\n```python\\nx = 5\\nresult = x  # The value of x is truthy, so result is also truthy\\n```\\n\\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\\n\\n```python\\nx = 5\\nresult = bool(x)  # Explicitly converting x to a boolean value\\n```\\n\\nThis ensures that the result is always a boolean value, regardless of the language\\'s truthiness and falsiness rules.'}],\n 'source': 'infini-instruct-top-500k',\n 'score': 5.212620735168457}"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"features = list(dataset.features.keys())\nprint(features)","metadata":{"id":"xYKmTDtkAnt5","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:10:20.581213Z","iopub.execute_input":"2024-11-15T03:10:20.581589Z","iopub.status.idle":"2024-11-15T03:10:20.589776Z","shell.execute_reply.started":"2024-11-15T03:10:20.581543Z","shell.execute_reply":"2024-11-15T03:10:20.588848Z"}},"outputs":[{"name":"stdout","text":"['conversations', 'source', 'score']\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## 04 Text Formatting","metadata":{"id":"Wq59WgYJCDY0"}},{"cell_type":"code","source":"def transform_conversations(example):\n  role_map = {\n    'human' : 'user',\n    'gpt' : 'assistant'\n  }\n\n  transformed_conversations = [\n    {\n      'role' : role_map.get(turn['from'], turn['from']),\n      'content' : turn['value']\n    }\n    for turn in example['conversations']\n  ]\n  return {'conversations': transformed_conversations}","metadata":{"id":"0wXJNFBWWNYP","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:10:20.590973Z","iopub.execute_input":"2024-11-15T03:10:20.591273Z","iopub.status.idle":"2024-11-15T03:10:20.600567Z","shell.execute_reply.started":"2024-11-15T03:10:20.591241Z","shell.execute_reply":"2024-11-15T03:10:20.599617Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"formatted_dataset = dataset.map(transform_conversations, remove_columns = features)\nformatted_dataset","metadata":{"id":"7TFGpGhoWS9e","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:10:20.601717Z","iopub.execute_input":"2024-11-15T03:10:20.602617Z","iopub.status.idle":"2024-11-15T03:10:21.174965Z","shell.execute_reply.started":"2024-11-15T03:10:20.602580Z","shell.execute_reply":"2024-11-15T03:10:21.173989Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['conversations'],\n    num_rows: 100000\n})"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"print(formatted_dataset[0]['conversations'])","metadata":{"id":"cZya4tPEWUc9","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:10:21.176304Z","iopub.execute_input":"2024-11-15T03:10:21.177024Z","iopub.status.idle":"2024-11-15T03:10:21.182451Z","shell.execute_reply.started":"2024-11-15T03:10:21.176975Z","shell.execute_reply":"2024-11-15T03:10:21.181512Z"}},"outputs":[{"name":"stdout","text":"[{'content': 'Explain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \\n\\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\\n\\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.', 'role': 'user'}, {'content': 'Boolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\\n\\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\\n\\n```python\\nx = 5\\nresult = not (x > 10)  # This expression evaluates to True\\n```\\n\\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\\n\\n```python\\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\\n```\\n\\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\\n\\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\\n\\n```python\\nif x != 0 and (y / x) > 10:\\n    # Perform some operation\\n```\\n\\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here\\'s an example in pseudocode:\\n\\n```\\nif x != 0 {\\n    if (y / x) > 10 {\\n        // Perform some operation\\n    }\\n}\\n```\\n\\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\\n\\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\\n\\n```python\\nx = 5\\nresult = x  # The value of x is truthy, so result is also truthy\\n```\\n\\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\\n\\n```python\\nx = 5\\nresult = bool(x)  # Explicitly converting x to a boolean value\\n```\\n\\nThis ensures that the result is always a boolean value, regardless of the language\\'s truthiness and falsiness rules.', 'role': 'assistant'}]\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"def format_conversation(example):\n  for entry in example['conversations']:\n    role = entry['role']\n    content = entry['content']\n\n    if role == 'user':\n      formatted_text = f\"<|start_header_id|>{role}<|end_header_id|>\\n\\n{content}\\n<|eot_id|>\"\n    elif role == 'assistant':\n      formatted_text += f\"<|start_header_id|>{role}<|end_header_id|>\\n\\n{content}\\n<|eot_id|>\"\n\n  return {'prompt': formatted_text}","metadata":{"id":"3bmXGueQWWzt","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:10:21.183866Z","iopub.execute_input":"2024-11-15T03:10:21.184241Z","iopub.status.idle":"2024-11-15T03:10:21.193082Z","shell.execute_reply.started":"2024-11-15T03:10:21.184191Z","shell.execute_reply":"2024-11-15T03:10:21.192239Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"formatted_dataset = formatted_dataset.map(\n  format_conversation,\n  remove_columns = list(formatted_dataset.features.keys())\n)\nformatted_dataset","metadata":{"id":"Z6sSaCr5eaL7","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:10:21.194258Z","iopub.execute_input":"2024-11-15T03:10:21.194550Z","iopub.status.idle":"2024-11-15T03:10:21.618442Z","shell.execute_reply.started":"2024-11-15T03:10:21.194517Z","shell.execute_reply":"2024-11-15T03:10:21.617449Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt'],\n    num_rows: 100000\n})"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"print(formatted_dataset[0]['prompt'])","metadata":{"id":"Kidf8H5zefDC","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:10:21.619511Z","iopub.execute_input":"2024-11-15T03:10:21.619806Z","iopub.status.idle":"2024-11-15T03:10:21.625289Z","shell.execute_reply.started":"2024-11-15T03:10:21.619774Z","shell.execute_reply":"2024-11-15T03:10:21.624394Z"}},"outputs":[{"name":"stdout","text":"<|start_header_id|>user<|end_header_id|>\n\nExplain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \n\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\n\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nBoolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\n\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\n\n```python\nx = 5\ny = 10\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\n```\n\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\n\n```python\nx = 5\ny = 10\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\n```\n\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\n\n```python\nx = 5\nresult = not (x > 10)  # This expression evaluates to True\n```\n\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\n\n```python\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\n```\n\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\n\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\n\n```python\nif x != 0 and (y / x) > 10:\n    # Perform some operation\n```\n\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here's an example in pseudocode:\n\n```\nif x != 0 {\n    if (y / x) > 10 {\n        // Perform some operation\n    }\n}\n```\n\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\n\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\n\n```python\nx = 5\nresult = x  # The value of x is truthy, so result is also truthy\n```\n\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\n\n```python\nx = 5\nresult = bool(x)  # Explicitly converting x to a boolean value\n```\n\nThis ensures that the result is always a boolean value, regardless of the language's truthiness and falsiness rules.\n<|eot_id|>\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"## 05 Tokenization","metadata":{"id":"UMhGDyBpCHoT"}},{"cell_type":"code","source":"def tokenize_data(example, max_length = max_length):\n  return tokenizer(example['prompt'], truncation = True, padding = 'max_length', max_length = max_length)","metadata":{"id":"m7bxU8fiewb7","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:10:21.626753Z","iopub.execute_input":"2024-11-15T03:10:21.627269Z","iopub.status.idle":"2024-11-15T03:10:21.636138Z","shell.execute_reply.started":"2024-11-15T03:10:21.627222Z","shell.execute_reply":"2024-11-15T03:10:21.635284Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"tokenized_dataset = formatted_dataset.map(tokenize_data, batched = True)#, remove_columns = 'text')\ntokenized_dataset","metadata":{"id":"M3BO26k-BmdS","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:10:21.637366Z","iopub.execute_input":"2024-11-15T03:10:21.637759Z","iopub.status.idle":"2024-11-15T03:12:12.630871Z","shell.execute_reply.started":"2024-11-15T03:10:21.637715Z","shell.execute_reply":"2024-11-15T03:12:12.629926Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0bb2360c5b54255a289bab3143d11a7"}},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 100000\n})"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"print(tokenized_dataset[0]['prompt'])","metadata":{"id":"wEHhMdV4pEFH","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:12:12.632071Z","iopub.execute_input":"2024-11-15T03:12:12.632415Z","iopub.status.idle":"2024-11-15T03:12:12.639672Z","shell.execute_reply.started":"2024-11-15T03:12:12.632380Z","shell.execute_reply":"2024-11-15T03:12:12.638482Z"}},"outputs":[{"name":"stdout","text":"<|start_header_id|>user<|end_header_id|>\n\nExplain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \n\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\n\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nBoolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\n\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\n\n```python\nx = 5\ny = 10\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\n```\n\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\n\n```python\nx = 5\ny = 10\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\n```\n\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\n\n```python\nx = 5\nresult = not (x > 10)  # This expression evaluates to True\n```\n\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\n\n```python\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\n```\n\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\n\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\n\n```python\nif x != 0 and (y / x) > 10:\n    # Perform some operation\n```\n\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here's an example in pseudocode:\n\n```\nif x != 0 {\n    if (y / x) > 10 {\n        // Perform some operation\n    }\n}\n```\n\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\n\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\n\n```python\nx = 5\nresult = x  # The value of x is truthy, so result is also truthy\n```\n\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\n\n```python\nx = 5\nresult = bool(x)  # Explicitly converting x to a boolean value\n```\n\nThis ensures that the result is always a boolean value, regardless of the language's truthiness and falsiness rules.\n<|eot_id|>\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"dataset = tokenized_dataset.train_test_split(test_size = 0.1, seed = 42)\ndataset","metadata":{"id":"C2m-e-ivDn1A","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:12:12.641245Z","iopub.execute_input":"2024-11-15T03:12:12.641771Z","iopub.status.idle":"2024-11-15T03:12:12.870809Z","shell.execute_reply.started":"2024-11-15T03:12:12.641734Z","shell.execute_reply":"2024-11-15T03:12:12.869832Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 90000\n    })\n    test: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 10000\n    })\n})"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"train_dataset = dataset['train']\ntest_dataset = dataset['test']\ntrain_dataset","metadata":{"id":"QHs-BnR_zd9C","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:12:12.871995Z","iopub.execute_input":"2024-11-15T03:12:12.872353Z","iopub.status.idle":"2024-11-15T03:12:12.878704Z","shell.execute_reply.started":"2024-11-15T03:12:12.872318Z","shell.execute_reply":"2024-11-15T03:12:12.877752Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 90000\n})"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"train_dataset.select(range(5)).to_pandas().head()","metadata":{"id":"-CUZuEENF2mW","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:12:12.879851Z","iopub.execute_input":"2024-11-15T03:12:12.880180Z","iopub.status.idle":"2024-11-15T03:12:12.916511Z","shell.execute_reply.started":"2024-11-15T03:12:12.880146Z","shell.execute_reply":"2024-11-15T03:12:12.915587Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"                                              prompt  \\\n0  <|start_header_id|>user<|end_header_id|>\\n\\nWh...   \n1  <|start_header_id|>user<|end_header_id|>\\n\\nUs...   \n2  <|start_header_id|>user<|end_header_id|>\\n\\nCr...   \n3  <|start_header_id|>user<|end_header_id|>\\n\\nWr...   \n4  <|start_header_id|>user<|end_header_id|>\\n\\nTh...   \n\n                                           input_ids  \\\n0  [49152, 49152, 49152, 49152, 49152, 49152, 491...   \n1  [49152, 49152, 49152, 49152, 49152, 49152, 491...   \n2  [49152, 49152, 49152, 49152, 49152, 49152, 491...   \n3  [49152, 49152, 49152, 49152, 49152, 49152, 491...   \n4  [49152, 49152, 49152, 49152, 49152, 49152, 491...   \n\n                                      attention_mask  \n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nWh...</td>\n      <td>[49152, 49152, 49152, 49152, 49152, 49152, 491...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nUs...</td>\n      <td>[49152, 49152, 49152, 49152, 49152, 49152, 491...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nCr...</td>\n      <td>[49152, 49152, 49152, 49152, 49152, 49152, 491...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nWr...</td>\n      <td>[49152, 49152, 49152, 49152, 49152, 49152, 491...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nTh...</td>\n      <td>[49152, 49152, 49152, 49152, 49152, 49152, 491...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"print(train_dataset[0]['prompt'])","metadata":{"id":"6PxxrK5Rd4gk","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:12:12.924385Z","iopub.execute_input":"2024-11-15T03:12:12.925154Z","iopub.status.idle":"2024-11-15T03:12:12.931091Z","shell.execute_reply.started":"2024-11-15T03:12:12.925116Z","shell.execute_reply":"2024-11-15T03:12:12.930115Z"}},"outputs":[{"name":"stdout","text":"<|start_header_id|>user<|end_header_id|>\n\nWhat is the algorithm to detect if a linked list contains a cycle, and if a cycle is present, determine the node at which the cycle begins?\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nThe algorithm to detect cycle in linked list is famously known as Floyd's Cycle-Finding Algorithm, or the Tortoise and the Hare algorithm.\n\nHere's how the algorithm works:\n\n1. Initialize two pointers, slow and fast at the head of the linked list.\n2. Move slow pointer by one and fast pointer by two. If there's a cycle in the list, the fast pointer will eventually meet the slow pointer.\n3. When they meet, reset the slow pointer to the head while leaving the fast pointer at the meeting point.\n4. Now, advance both slow and fast pointers at the same pace, one step at a time. The point at which they meet now is the start of the cycle.\n\nHere's the code in Python:\n\n```python\ndef detectCycle(head):\n    slow = fast = head\n    while fast and fast.next:\n        slow = slow.next\n        fast = fast.next.next\n        # cycle detected\n        if slow == fast:\n            break\n    else:\n        # No cycle\n        return None\n\n    # Find the starting node\n    slow = head\n    while slow != fast:\n        slow = slow.next\n        fast = fast.next\n    return slow\n```\n\nThis code returns the node at which the cycle begins. If there is no cycle, it returns None.\n\nAlso, the time complexity of this algorithm is O(n) and the space complexity is O(1), where n is the number of elements in the linked list.\n<|eot_id|>\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"print(train_dataset[0]['input_ids'])","metadata":{"id":"HR79ppIiE78f","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:12:12.932317Z","iopub.execute_input":"2024-11-15T03:12:12.932698Z","iopub.status.idle":"2024-11-15T03:12:12.942844Z","shell.execute_reply.started":"2024-11-15T03:12:12.932652Z","shell.execute_reply":"2024-11-15T03:12:12.941842Z"}},"outputs":[{"name":"stdout","text":"[49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 49152, 44, 108, 3738, 79, 12476, 79, 311, 108, 46, 4093, 44, 108, 486, 79, 12476, 79, 311, 108, 46, 198, 198, 1780, 314, 260, 7748, 288, 4087, 585, 253, 5150, 1398, 3593, 253, 4834, 28, 284, 585, 253, 4834, 314, 1386, 28, 3346, 260, 5994, 418, 527, 260, 4834, 5634, 47, 198, 44, 108, 85, 320, 79, 311, 108, 21198, 108, 3738, 79, 12476, 79, 311, 108, 46, 520, 9531, 44, 108, 486, 79, 12476, 79, 311, 108, 46, 198, 198, 504, 7748, 288, 4087, 4834, 281, 5150, 1398, 314, 24715, 1343, 347, 41498, 506, 22996, 29, 26904, 34644, 28, 355, 260, 30830, 20877, 284, 260, 41493, 7748, 30, 198, 198, 4590, 506, 638, 260, 7748, 1806, 42, 1116, 33, 30, 33066, 827, 35400, 28, 2890, 284, 3538, 418, 260, 1680, 282, 260, 5150, 1398, 30, 198, 34, 30, 8669, 2890, 26116, 411, 582, 284, 3538, 26116, 411, 827, 30, 1094, 665, 506, 253, 4834, 281, 260, 1398, 28, 260, 3538, 26116, 523, 4380, 2220, 260, 2890, 26116, 30, 198, 35, 30, 1550, 502, 2220, 28, 15453, 260, 2890, 26116, 288, 260, 1680, 979, 5170, 260, 3538, 26116, 418, 260, 4751, 1225, 30, 198, 36, 30, 3569, 28, 4408, 1062, 2890, 284, 3538, 35400, 418, 260, 1142, 9953, 28, 582, 1833, 418, 253, 655, 30, 378, 1225, 418, 527, 502, 2220, 1209, 314, 260, 1120, 282, 260, 4834, 30, 198, 198, 4590, 506, 260, 2909, 281, 5905, 42, 198, 198, 3725, 5367, 198, 1604, 4087, 51, 18050, 24, 2699, 727, 472, 2890, 446, 3538, 446, 1680, 472, 979, 3538, 284, 3538, 30, 11282, 42, 448, 2890, 446, 2890, 30, 11282, 448, 3538, 446, 3538, 30, 11282, 30, 11282, 448, 907, 4834, 8751, 448, 585, 2890, 1758, 3538, 42, 629, 2373, 472, 1745, 42, 448, 907, 2838, 4834, 448, 1003, 1943, 1004, 907, 7985, 260, 4335, 5994, 472, 2890, 446, 1680, 472, 979, 2890, 6541, 3538, 42, 448, 2890, 446, 2890, 30, 11282, 448, 3538, 446, 3538, 30, 11282, 472, 1003, 2890, 198, 3725, 198, 198, 1348, 2909, 6765, 260, 5994, 418, 527, 260, 4834, 5634, 30, 1094, 665, 314, 787, 4834, 28, 357, 6765, 1943, 30, 198, 198, 9330, 28, 260, 655, 7147, 282, 451, 7748, 314, 492, 24, 94, 25, 284, 260, 1898, 7147, 314, 492, 24, 33, 643, 837, 304, 314, 260, 1230, 282, 2728, 281, 260, 5150, 1398, 30, 198, 44, 108, 85, 320, 79, 311, 108, 46]\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"print(train_dataset[0]['attention_mask'])","metadata":{"id":"xGmCvvZTE82D","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:12:12.944101Z","iopub.execute_input":"2024-11-15T03:12:12.944793Z","iopub.status.idle":"2024-11-15T03:12:12.954864Z","shell.execute_reply.started":"2024-11-15T03:12:12.944683Z","shell.execute_reply":"2024-11-15T03:12:12.953914Z"}},"outputs":[{"name":"stdout","text":"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"## 06 Data Collator Set Up","metadata":{"id":"JFX4u0vc0UkS"}},{"cell_type":"code","source":"#data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n#data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer)\ndata_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)","metadata":{"id":"F-mkiTYw0cZi","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:12:12.956002Z","iopub.execute_input":"2024-11-15T03:12:12.956362Z","iopub.status.idle":"2024-11-15T03:12:12.964217Z","shell.execute_reply.started":"2024-11-15T03:12:12.956328Z","shell.execute_reply":"2024-11-15T03:12:12.963178Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"## 07 Evaluation Metrics Set Up","metadata":{"id":"hP1Mu0J6CTCb"}},{"cell_type":"code","source":"def compute_metrics(p: EvalPrediction):\n  preds = np.argmax(p.predictions, axis = 1)\n  precision, recall, f1, _ = precision_recall_fscore_support(\n    p.label_ids,\n    preds,\n    average = 'weighted'\n  )\n  matrix = {\n    'accuracy': accuracy_score(p.label_ids, preds),\n    'f1': f1, 'precision': precision,\n    'recall': recall\n  }\n  return matrix","metadata":{"id":"wzNdWpCI0c7a","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:12:12.965330Z","iopub.execute_input":"2024-11-15T03:12:12.965846Z","iopub.status.idle":"2024-11-15T03:12:12.975527Z","shell.execute_reply.started":"2024-11-15T03:12:12.965800Z","shell.execute_reply":"2024-11-15T03:12:12.974693Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"tEkgHY4fxFIJ","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:12:12.977011Z","iopub.execute_input":"2024-11-15T03:12:12.977444Z","iopub.status.idle":"2024-11-15T03:12:12.986163Z","shell.execute_reply.started":"2024-11-15T03:12:12.977400Z","shell.execute_reply":"2024-11-15T03:12:12.985274Z"}},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":"## 08 Set Up PEFT / LoRA / QLoRA","metadata":{"id":"VLFCnU8-ZoUa"}},{"cell_type":"code","source":"lora_alpha = 16\nlora_dropout = 0.1\nlora_r = 64\ntarget_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                  \"gate_proj\", \"up_proj\", \"down_proj\",]\npeft_config = LoraConfig(\n  lora_alpha = lora_alpha,\n  lora_dropout = lora_dropout,\n  r = lora_r,\n  bias = 'none',\n  task_type = 'CAUSAL_LM',\n  target_modules = target_modules,\n)","metadata":{"id":"67HK09faZqQh","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:12:12.987341Z","iopub.execute_input":"2024-11-15T03:12:12.987941Z","iopub.status.idle":"2024-11-15T03:12:12.997903Z","shell.execute_reply.started":"2024-11-15T03:12:12.987895Z","shell.execute_reply":"2024-11-15T03:12:12.996999Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"peft_model = get_peft_model(model, peft_config, adapter_name = 'math')\npeft_model.print_trainable_parameters()","metadata":{"id":"3ZPOifXCZuhg","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:12:12.998878Z","iopub.execute_input":"2024-11-15T03:12:12.999176Z","iopub.status.idle":"2024-11-15T03:12:14.391640Z","shell.execute_reply.started":"2024-11-15T03:12:12.999144Z","shell.execute_reply":"2024-11-15T03:12:14.390549Z"}},"outputs":[{"name":"stdout","text":"trainable params: 72,351,744 || all params: 1,783,730,176 || trainable%: 4.0562\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"## 09 Training Model","metadata":{"id":"CVr-LToX1XCl"}},{"cell_type":"code","source":"model","metadata":{"id":"ikF6Yfkz1myd","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:12:14.393105Z","iopub.execute_input":"2024-11-15T03:12:14.393544Z","iopub.status.idle":"2024-11-15T03:12:14.415111Z","shell.execute_reply.started":"2024-11-15T03:12:14.393495Z","shell.execute_reply":"2024-11-15T03:12:14.414011Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(49153, 2048, padding_idx=49152)\n    (layers): ModuleList(\n      (0-23): 24 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n            (lora_dropout): ModuleDict(\n              (math): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (math): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (math): Linear(in_features=64, out_features=2048, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (k_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n            (lora_dropout): ModuleDict(\n              (math): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (math): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (math): Linear(in_features=64, out_features=2048, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (v_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n            (lora_dropout): ModuleDict(\n              (math): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (math): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (math): Linear(in_features=64, out_features=2048, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (o_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n            (lora_dropout): ModuleDict(\n              (math): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (math): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (math): Linear(in_features=64, out_features=2048, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n            (lora_dropout): ModuleDict(\n              (math): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (math): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (math): Linear(in_features=64, out_features=8192, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (up_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n            (lora_dropout): ModuleDict(\n              (math): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (math): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (math): Linear(in_features=64, out_features=8192, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (down_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=8192, out_features=2048, bias=False)\n            (lora_dropout): ModuleDict(\n              (math): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (math): Linear(in_features=8192, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (math): Linear(in_features=64, out_features=2048, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=2048, out_features=49153, bias=False)\n)"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"uhliEMyp1thd","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:12:14.416264Z","iopub.execute_input":"2024-11-15T03:12:14.416687Z","iopub.status.idle":"2024-11-15T03:12:14.441022Z","shell.execute_reply.started":"2024-11-15T03:12:14.416635Z","shell.execute_reply":"2024-11-15T03:12:14.439373Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 978423808\nTrainable parameters : 72351744\nTrainable percentage: 7.39%\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"Xn5zb6xWJtu-","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:12:14.442554Z","iopub.execute_input":"2024-11-15T03:12:14.443625Z","iopub.status.idle":"2024-11-15T03:12:14.447823Z","shell.execute_reply.started":"2024-11-15T03:12:14.443583Z","shell.execute_reply":"2024-11-15T03:12:14.446767Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"save_path = './model'\n\nbatch_size = 2\nmax_steps = 200\ntraining_args = TrainingArguments(\n  output_dir = save_path,\n  gradient_accumulation_steps = 4,\n  evaluation_strategy = 'steps',\n  do_eval = True,\n  per_device_train_batch_size = batch_size,\n  per_device_eval_batch_size = 4,\n  log_level = 'debug',\n  save_strategy = 'no',\n  save_total_limit = 2,\n  save_safetensors = False,\n  fp16 = True,\n  logging_steps = 20,\n  learning_rate = 2e-5,\n  eval_steps = 20,\n  max_steps = max_steps,\n  warmup_steps = 30,\n  lr_scheduler_type = 'cosine',\n)\ntraining_args","metadata":{"id":"93ffvb0d4cG6","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:12:14.449027Z","iopub.execute_input":"2024-11-15T03:12:14.449397Z","iopub.status.idle":"2024-11-15T03:12:14.495093Z","shell.execute_reply.started":"2024-11-15T03:12:14.449346Z","shell.execute_reply":"2024-11-15T03:12:14.494094Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=20,\neval_strategy=steps,\neval_use_gather_object=False,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=debug,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=./model/runs/Nov15_03-12-14_becd1153e656,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=20,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=cosine,\nmax_grad_norm=1.0,\nmax_steps=200,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=adamw_torch,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=./model,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=2,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=./model,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=False,\nsave_steps=500,\nsave_strategy=no,\nsave_total_limit=2,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=30,\nweight_decay=0.0,\n)"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"trainer = SFTTrainer(\n  model = model,\n  train_dataset = train_dataset,#.select(range(10000)),\n  eval_dataset = test_dataset.select(range(200)),\n  dataset_text_field = 'prompt',\n  max_seq_length = max_length,\n  tokenizer = tokenizer,\n  args = training_args,\n  peft_config = peft_config,\n)\ntrainer","metadata":{"id":"EsKeJE3SMdk7","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:12:14.496236Z","iopub.execute_input":"2024-11-15T03:12:14.496552Z","iopub.status.idle":"2024-11-15T03:12:16.237147Z","shell.execute_reply.started":"2024-11-15T03:12:14.496516Z","shell.execute_reply":"2024-11-15T03:12:16.236231Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:403: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\nUsing auto half precision backend\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"<trl.trainer.sft_trainer.SFTTrainer at 0x7e56c42bcaf0>"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"MZVoQX8V1cI3","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T03:12:16.238293Z","iopub.execute_input":"2024-11-15T03:12:16.238602Z","iopub.status.idle":"2024-11-15T04:15:49.181470Z","shell.execute_reply.started":"2024-11-15T03:12:16.238567Z","shell.execute_reply":"2024-11-15T04:15:49.180488Z"}},"outputs":[{"name":"stderr","text":"Currently training with a batch size of: 2\nThe following columns in the training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n***** Running training *****\n  Num examples = 90,000\n  Num Epochs = 1\n  Instantaneous batch size per device = 2\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 4\n  Total optimization steps = 200\n  Number of trainable parameters = 72,351,744\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mterlupakan100\u001b[0m (\u001b[33mterlupakan100-\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113588522221107, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c103961ce434a15a56fa6af0c3129aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241115_031218-3rg7bo2q</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/terlupakan100-/huggingface/runs/3rg7bo2q' target=\"_blank\">./model</a></strong> to <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/terlupakan100-/huggingface/runs/3rg7bo2q' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface/runs/3rg7bo2q</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 1:03:14, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>1.240400</td>\n      <td>1.236964</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.180900</td>\n      <td>1.200868</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.166300</td>\n      <td>1.124003</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>1.102400</td>\n      <td>1.061197</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.960200</td>\n      <td>1.002636</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>1.008700</td>\n      <td>0.969619</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.948200</td>\n      <td>0.957973</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.966600</td>\n      <td>0.953145</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.892900</td>\n      <td>0.951403</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.923900</td>\n      <td>0.951135</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=200, training_loss=1.0390537357330323, metrics={'train_runtime': 3812.4675, 'train_samples_per_second': 0.42, 'train_steps_per_second': 0.052, 'total_flos': 1.72564471087104e+16, 'train_loss': 1.0390537357330323, 'epoch': 0.017777777777777778})"},"metadata":{}}],"execution_count":41},{"cell_type":"markdown","source":"## 10 Model Evaluation","metadata":{"id":"v5N6fZsU1xiG"}},{"cell_type":"code","source":"evaluation_results = trainer.evaluate()\nprint('Evaluation Results:', evaluation_results)","metadata":{"id":"5d6DT3o0113O","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T04:15:49.182662Z","iopub.execute_input":"2024-11-15T04:15:49.183023Z","iopub.status.idle":"2024-11-15T04:17:56.546779Z","shell.execute_reply.started":"2024-11-15T04:15:49.182988Z","shell.execute_reply":"2024-11-15T04:17:56.545863Z"}},"outputs":[{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 02:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation Results: {'eval_loss': 0.9511353373527527, 'eval_runtime': 127.3493, 'eval_samples_per_second': 1.57, 'eval_steps_per_second': 0.393, 'epoch': 0.017777777777777778}\n","output_type":"stream"}],"execution_count":42},{"cell_type":"markdown","source":"## 11 Save Model","metadata":{"id":"PjTPWhCj4JQj"}},{"cell_type":"code","source":"save_model = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\nsave_model.save_pretrained(save_path)","metadata":{"id":"OKAmko8h2VeV","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T04:17:56.548179Z","iopub.execute_input":"2024-11-15T04:17:56.548859Z","iopub.status.idle":"2024-11-15T04:17:58.057086Z","shell.execute_reply.started":"2024-11-15T04:17:56.548811Z","shell.execute_reply":"2024-11-15T04:17:58.056270Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--SmolLM2-1.7B-Instruct/snapshots/88449834338d898a9eaaeb1cbec167d0a296e2a6/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"HuggingFaceTB/SmolLM2-1.7B-Instruct\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"head_dim\": 64,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 2048,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 8192,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 24,\n  \"num_key_value_heads\": 32,\n  \"pad_token_id\": 49152,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": null,\n  \"rope_theta\": 130000,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers.js_config\": {\n    \"kv_cache_dtype\": {\n      \"fp16\": \"float16\",\n      \"q4f16\": \"float16\"\n    }\n  },\n  \"transformers_version\": \"4.46.2\",\n  \"unsloth_fixed\": true,\n  \"use_cache\": true,\n  \"vocab_size\": 49153\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--SmolLM2-1.7B-Instruct/snapshots/88449834338d898a9eaaeb1cbec167d0a296e2a6/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"HuggingFaceTB/SmolLM2-1.7B-Instruct\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"head_dim\": 64,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 2048,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 8192,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 24,\n  \"num_key_value_heads\": 32,\n  \"pad_token_id\": 49152,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": null,\n  \"rope_theta\": 130000,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers.js_config\": {\n    \"kv_cache_dtype\": {\n      \"fp16\": \"float16\",\n      \"q4f16\": \"float16\"\n    }\n  },\n  \"transformers_version\": \"4.46.2\",\n  \"unsloth_fixed\": true,\n  \"use_cache\": true,\n  \"vocab_size\": 49153\n}\n\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"## 12 Load PEFT Model","metadata":{"id":"3NhWAM5h9Rn5"}},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"dlTaH2HoC26T","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T04:17:58.058234Z","iopub.execute_input":"2024-11-15T04:17:58.058549Z","iopub.status.idle":"2024-11-15T04:17:58.503764Z","shell.execute_reply.started":"2024-11-15T04:17:58.058510Z","shell.execute_reply":"2024-11-15T04:17:58.502656Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"peft_model = PeftModel.from_pretrained(model, save_path)\npeft_model","metadata":{"id":"Nz2HT8nb9XJa","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T04:17:58.505152Z","iopub.execute_input":"2024-11-15T04:17:58.505562Z","iopub.status.idle":"2024-11-15T04:17:59.720466Z","shell.execute_reply.started":"2024-11-15T04:17:58.505513Z","shell.execute_reply":"2024-11-15T04:17:59.719543Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(49153, 2048, padding_idx=49152)\n        (layers): ModuleList(\n          (0-23): 24 x LlamaDecoderLayer(\n            (self_attn): LlamaSdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (math): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (math): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (math): Linear(in_features=64, out_features=2048, bias=False)\n                  (default): Linear(in_features=64, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (math): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (math): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (math): Linear(in_features=64, out_features=2048, bias=False)\n                  (default): Linear(in_features=64, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (math): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (math): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (math): Linear(in_features=64, out_features=2048, bias=False)\n                  (default): Linear(in_features=64, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (math): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (math): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (math): Linear(in_features=64, out_features=2048, bias=False)\n                  (default): Linear(in_features=64, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n                (lora_dropout): ModuleDict(\n                  (math): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (math): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (math): Linear(in_features=64, out_features=8192, bias=False)\n                  (default): Linear(in_features=64, out_features=8192, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n                (lora_dropout): ModuleDict(\n                  (math): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (math): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (math): Linear(in_features=64, out_features=8192, bias=False)\n                  (default): Linear(in_features=64, out_features=8192, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=8192, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (math): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (math): Linear(in_features=8192, out_features=64, bias=False)\n                  (default): Linear(in_features=8192, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (math): Linear(in_features=64, out_features=2048, bias=False)\n                  (default): Linear(in_features=64, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=2048, out_features=49153, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"eepaD3O-9t3H","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T04:17:59.721705Z","iopub.execute_input":"2024-11-15T04:17:59.722023Z","iopub.status.idle":"2024-11-15T04:17:59.747811Z","shell.execute_reply.started":"2024-11-15T04:17:59.721990Z","shell.execute_reply":"2024-11-15T04:17:59.746874Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 1050775552\nTrainable parameters : 0\nTrainable percentage: 0.00%\n","output_type":"stream"}],"execution_count":46},{"cell_type":"markdown","source":"## 13 Pre Test & Post Test","metadata":{"id":"GrXYkyb89UJQ"}},{"cell_type":"code","source":"def pre_assistant(prompt):\n  messages = [\n    {'role' : 'human', 'content' : prompt},\n  ]\n  inputs = tokenizer.apply_chat_template(\n    messages,\n    tokenize = True,\n    add_generation_prompt = True,\n    return_tensors = 'pt',\n  ).to('cuda')\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = model.generate(\n    input_ids = inputs,\n    generation_config = generation_config\n  )\n  return print(tokenizer.decode(outputs[0]))#, skip_special_tokens = True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-15T04:17:59.749133Z","iopub.execute_input":"2024-11-15T04:17:59.749530Z","iopub.status.idle":"2024-11-15T04:17:59.756684Z","shell.execute_reply.started":"2024-11-15T04:17:59.749474Z","shell.execute_reply":"2024-11-15T04:17:59.755828Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"def post_assistant(prompt):\n  messages = [\n    {'role' : 'human', 'content' : prompt},\n  ]\n  inputs = tokenizer.apply_chat_template(\n    messages,\n    tokenize = True,\n    add_generation_prompt = True,\n    return_tensors = 'pt',\n  ).to('cuda')\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = peft_model.generate(\n    input_ids = inputs,\n    generation_config = generation_config\n  )\n  return print(tokenizer.decode(outputs[0]))#, skip_special_tokens = True))","metadata":{"id":"lgVU8Ci9RMu6","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T04:17:59.757909Z","iopub.execute_input":"2024-11-15T04:17:59.758222Z","iopub.status.idle":"2024-11-15T04:17:59.771769Z","shell.execute_reply.started":"2024-11-15T04:17:59.758189Z","shell.execute_reply":"2024-11-15T04:17:59.771027Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"prompt = '''\nSummarize the following legal text in a few sentences:\n'In the case of John Doe v. XYZ Corp, the plaintiff, John Doe, entered into a formal service contract with XYZ Corp in January 2022. The agreement stipulated a one-year commitment for IT support services, with John Doe providing on-site troubleshooting, software updates, and system maintenance. XYZ Corp agreed to pay a fixed monthly retainer along with additional fees for after-hours support. However, in June 2022, XYZ Corp terminated the contract without prior notice, claiming that an unexpected downturn in business operations left them financially unable to continue. The plaintiff alleges wrongful termination, asserting that XYZ Corp failed to adhere to the 60-day notice clause outlined in the contract. Additionally, the plaintiff contends that the early termination damaged his professional reputation and resulted in significant financial losses, including missed client opportunities and incurred expenses for certifications specific to XYZ Corp’s systems. John Doe is seeking compensation for the remaining contract balance, damages for reputational harm, and reimbursement for training and certification costs required under the agreement.\n'''\npre_assistant(prompt)\nprint(100 * '=')\npost_assistant(prompt)","metadata":{"id":"JlEhdEGGTN6T","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T04:17:59.772815Z","iopub.execute_input":"2024-11-15T04:17:59.773188Z","iopub.status.idle":"2024-11-15T04:18:19.785833Z","shell.execute_reply.started":"2024-11-15T04:17:59.773154Z","shell.execute_reply":"2024-11-15T04:18:19.784770Z"}},"outputs":[{"name":"stderr","text":"The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","output_type":"stream"},{"name":"stdout","text":"<|im_start|>system\nYou are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\n<|im_start|>human\n\nSummarize the following legal text in a few sentences:\n'In the case of John Doe v. XYZ Corp, the plaintiff, John Doe, entered into a formal service contract with XYZ Corp in January 2022. The agreement stipulated a one-year commitment for IT support services, with John Doe providing on-site troubleshooting, software updates, and system maintenance. XYZ Corp agreed to pay a fixed monthly retainer along with additional fees for after-hours support. However, in June 2022, XYZ Corp terminated the contract without prior notice, claiming that an unexpected downturn in business operations left them financially unable to continue. The plaintiff alleges wrongful termination, asserting that XYZ Corp failed to adhere to the 60-day notice clause outlined in the contract. Additionally, the plaintiff contends that the early termination damaged his professional reputation and resulted in significant financial losses, including missed client opportunities and incurred expenses for certifications specific to XYZ Corp’s systems. John Doe is seeking compensation for the remaining contract balance, damages for reputational harm, and reimbursement for training and certification costs required under the agreement.\n<|im_end|>\n<|im_start|>assistant\nJohn Doe entered into a service contract with XYZ Corp in January 2022, agreeing to IT support services for a one-year period. The contract included a fixed monthly retainer and additional fees for after-hours support. However, XYZ Corp terminated the contract without notice in June 2022, citing financial difficulties. John Doe alleges wrongful termination and seeks compensation for the remaining contract balance, damages for reputational harm, and reimbursement for training and certification costs.<|im_end|>\n====================================================================================================\n<|im_start|>system\nYou are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\n<|im_start|>human\n\nSummarize the following legal text in a few sentences:\n'In the case of John Doe v. XYZ Corp, the plaintiff, John Doe, entered into a formal service contract with XYZ Corp in January 2022. The agreement stipulated a one-year commitment for IT support services, with John Doe providing on-site troubleshooting, software updates, and system maintenance. XYZ Corp agreed to pay a fixed monthly retainer along with additional fees for after-hours support. However, in June 2022, XYZ Corp terminated the contract without prior notice, claiming that an unexpected downturn in business operations left them financially unable to continue. The plaintiff alleges wrongful termination, asserting that XYZ Corp failed to adhere to the 60-day notice clause outlined in the contract. Additionally, the plaintiff contends that the early termination damaged his professional reputation and resulted in significant financial losses, including missed client opportunities and incurred expenses for certifications specific to XYZ Corp’s systems. John Doe is seeking compensation for the remaining contract balance, damages for reputational harm, and reimbursement for training and certification costs required under the agreement.\n<|im_end|>\n<|im_start|>assistant\nJohn Doe entered into a service contract with XYZ Corp in January 2022, agreeing to IT support services for a one-year period. The contract included a fixed monthly retainer and additional fees for after-hours support. However, XYZ Corp terminated the contract without notice in June 2022, citing financial difficulties. John Doe alleges wrongful termination and seeks compensation for the remaining contract balance, damages for reputational harm, and reimbursement for training and certification costs.<|im_end|>\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"prompt = \"What are the legal implications if a party violates a confidentiality agreement in the context of contract law? For example, consider a scenario where a contractor working with Tech Innovators Inc. shares proprietary technology information with a competitor. Explain in detail and cite relevant case law where possible.\"\npre_assistant(prompt)\nprint(100 * '=')\npost_assistant(prompt)","metadata":{"id":"BxmnFTADTQsT","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T04:18:19.787123Z","iopub.execute_input":"2024-11-15T04:18:19.787439Z","iopub.status.idle":"2024-11-15T04:19:56.265527Z","shell.execute_reply.started":"2024-11-15T04:18:19.787405Z","shell.execute_reply":"2024-11-15T04:19:56.264532Z"}},"outputs":[{"name":"stdout","text":"<|im_start|>system\nYou are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\n<|im_start|>human\nWhat are the legal implications if a party violates a confidentiality agreement in the context of contract law? For example, consider a scenario where a contractor working with Tech Innovators Inc. shares proprietary technology information with a competitor. Explain in detail and cite relevant case law where possible.<|im_end|>\n<|im_start|>assistant\nIn contract law, a confidentiality agreement, also known as a non-disclosure agreement (NDA), is a legally binding contract that requires one party to keep certain information secret. If a party violates a confidentiality agreement, it can lead to severe legal implications.\n\nThe legal implications of violating a confidentiality agreement can be severe, depending on the specific circumstances and the laws of the jurisdiction. However, generally, the consequences can be categorized into three main areas: \n\n1. Breach of Contract: If a party breaches a confidentiality agreement, it can lead to the termination of the contract. The breaching party may be liable for damages, including compensatory damages, which are intended to compensate the non-breaching party for the harm caused by the breach.\n\n2. Infringement of Intellectual Property Rights: If a party shares confidential information with a competitor, it can infringe on the intellectual property rights of the contracting party. This can lead to legal action for damages, including injunctive relief, which is a court order to stop the infringing party from continuing the infringing activity.\n\n3. Liability for Trade Secrets: If a party shares confidential information with a competitor, it can lead to the theft of trade secrets. In this case, the non-breaching party may be able to seek injunctive relief to stop the infringing party from using the stolen trade secrets.\n\nIn the context of the scenario you described, if the contractor shares proprietary technology information with a competitor, it can lead to the theft of trade secrets. This can result in the competitor using the stolen information to gain a competitive advantage, which can lead to financial loss for the contracting party.\n\nIn relevant case law, there are several examples of parties being held liable for violating confidentiality agreements. For instance, in the case of *Smith v. Miller*, the court held that a party who breaches a confidentiality agreement can be liable for damages, including compensatory damages, which are intended to compensate the non-breaching party for the harm caused by the breach.\n\nIn the case of *Smith v. Miller*, the court also held that a party who breaches a confidentiality agreement can be liable for damages, including injunctive relief, which is a court order to stop the infringing party from continuing the infringing activity.\n\nIn conclusion, violating a confidentiality agreement can have severe legal implications, depending on the specific circumstances and the laws of the jurisdiction. It is crucial for parties to ensure that they comply with confidentiality agreements to avoid such consequences.<|im_end|>\n====================================================================================================\n<|im_start|>system\nYou are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\n<|im_start|>human\nWhat are the legal implications if a party violates a confidentiality agreement in the context of contract law? For example, consider a scenario where a contractor working with Tech Innovators Inc. shares proprietary technology information with a competitor. Explain in detail and cite relevant case law where possible.<|im_end|>\n<|im_start|>assistant\nIn contract law, a confidentiality agreement, also known as a non-disclosure agreement (NDA), is a legally binding contract that requires one party to keep certain information secret. If a party violates a confidentiality agreement, it can lead to severe legal implications.\n\nThe legal implications of violating a confidentiality agreement can be severe, depending on the specific circumstances and the laws of the jurisdiction. However, generally, the consequences can be categorized into three main areas: \n\n1. Breach of Contract: If a party breaches a confidentiality agreement, it can lead to the termination of the contract. The breaching party may be liable for damages, including compensatory damages, which are intended to compensate the non-breaching party for the harm caused by the breach.\n\n2. Infringement of Intellectual Property Rights: If a party shares confidential information with a competitor, it can infringe on the intellectual property rights of the contracting party. This can lead to legal action for damages, including injunctive relief, which is a court order to stop the infringing party from continuing the infringing activity.\n\n3. Liability for Trade Secrets: If a party shares confidential information with a competitor, it can lead to the theft of trade secrets. In this case, the non-breaching party may be able to seek injunctive relief to stop the infringing party from using the stolen trade secrets.\n\nIn the context of the scenario you described, if the contractor shares proprietary technology information with a competitor, it can lead to the theft of trade secrets. This can result in the competitor using the stolen information to gain a competitive advantage, which can lead to financial loss for the contracting party.\n\nIn relevant case law, there are several examples of parties being held liable for violating confidentiality agreements. For instance, in the case of *Smith v. Miller*, the court held that a party who breaches a confidentiality agreement can be liable for damages, including compensatory damages, which are intended to compensate the non-breaching party for the harm caused by the breach.\n\nIn the case of *Smith v. Miller*, the court also held that a party who breaches a confidentiality agreement can be liable for damages, including injunctive relief, which is a court order to stop the infringing party from continuing the infringing activity.\n\nIn conclusion, violating a confidentiality agreement can have severe legal implications, depending on the specific circumstances and the laws of the jurisdiction. It is crucial for parties to ensure that they comply with confidentiality agreements to avoid such consequences.<|im_end|>\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"prompt = \"Rephrase the following legal statement to make it more understandable for a general audience: 'Under the terms of the non-compete agreement, the defendant is barred from engaging in any business that competes with the plaintiff's business within a 50-mile radius for two years following the termination of employment.' Retain all key information while simplifying the language.\"\npre_assistant(prompt)\nprint(100 * '=')\npost_assistant(prompt)","metadata":{"id":"RDONbvZKTTqs","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T04:19:56.266873Z","iopub.execute_input":"2024-11-15T04:19:56.267214Z","iopub.status.idle":"2024-11-15T04:20:04.863037Z","shell.execute_reply.started":"2024-11-15T04:19:56.267178Z","shell.execute_reply":"2024-11-15T04:20:04.862114Z"}},"outputs":[{"name":"stdout","text":"<|im_start|>system\nYou are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\n<|im_start|>human\nRephrase the following legal statement to make it more understandable for a general audience: 'Under the terms of the non-compete agreement, the defendant is barred from engaging in any business that competes with the plaintiff's business within a 50-mile radius for two years following the termination of employment.' Retain all key information while simplifying the language.<|im_end|>\n<|im_start|>assistant\n'The agreement says the person who broke the rules can't start a business that competes with the other person's business within a 50-mile area for two years after they stop working for the other person.'<|im_end|>\n====================================================================================================\n<|im_start|>system\nYou are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\n<|im_start|>human\nRephrase the following legal statement to make it more understandable for a general audience: 'Under the terms of the non-compete agreement, the defendant is barred from engaging in any business that competes with the plaintiff's business within a 50-mile radius for two years following the termination of employment.' Retain all key information while simplifying the language.<|im_end|>\n<|im_start|>assistant\n'The agreement says the person who broke the rules can't start a business that competes with the other person's business within a 50-mile area for two years after they stop working for the other person.'<|im_end|>\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"prompt = \"In the case where a defendant claims breach of contract due to unforeseeable events, how does the principle of 'force majeure' apply? For instance, if a company was unable to deliver contracted goods due to a natural disaster, provide a detailed explanation and outline any relevant conditions under which the force majeure principle might or might not be applicable.\"\npre_assistant(prompt)\nprint(100 * '=')\npost_assistant(prompt)","metadata":{"id":"p7dBkB_7TjZY","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T04:20:04.864537Z","iopub.execute_input":"2024-11-15T04:20:04.865229Z","iopub.status.idle":"2024-11-15T04:22:34.394952Z","shell.execute_reply.started":"2024-11-15T04:20:04.865178Z","shell.execute_reply":"2024-11-15T04:22:34.393090Z"}},"outputs":[{"name":"stdout","text":"<|im_start|>system\nYou are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\n<|im_start|>human\nIn the case where a defendant claims breach of contract due to unforeseeable events, how does the principle of 'force majeure' apply? For instance, if a company was unable to deliver contracted goods due to a natural disaster, provide a detailed explanation and outline any relevant conditions under which the force majeure principle might or might not be applicable.<|im_end|>\n<|im_start|>assistant\nThe principle of force majeure is a legal doctrine that excuses a breach of contract due to unforeseen events beyond the control of the parties involved. The term \"force majeure\" is French for \"greater force\" and refers to events that are beyond the control of the parties and are therefore beyond the scope of the contract.\n\nIn the case of a breach of contract due to unforeseeable events, the principle of force majeure can be applied in the following ways:\n\n1. Natural Disasters: If a natural disaster such as a hurricane, earthquake, flood, or wildfire occurs, the principle of force majeure can be applied. The event is beyond the control of the parties and is therefore beyond the scope of the contract. For example, if a company was contracted to deliver goods to a client, but the goods were destroyed in a hurricane, the principle of force majeure can be applied.\n\n2. War or Terrorism: If a war or terrorism occurs, the principle of force majeure can be applied. The event is beyond the control of the parties and is therefore beyond the scope of the contract. For example, if a company was contracted to deliver goods to a client, but the goods were destroyed in a bombing, the principle of force majeure can be applied.\n\n3. Public Health or Safety: If a public health or safety issue occurs, such as a pandemic or a major health crisis, the principle of force majeure can be applied. The event is beyond the control of the parties and is therefore beyond the scope of the contract. For example, if a company was contracted to deliver goods to a client, but the goods were destroyed due to a pandemic, the principle of force majeure can be applied.\n\n4. Governmental Actions: If a governmental action, such as a government shutdown or a change in laws, occurs, the principle of force majeure can be applied. The event is beyond the control of the parties and is therefore beyond the scope of the contract. For example, if a company was contracted to deliver goods to a client, but the goods were destroyed due to a government shutdown, the principle of force majeure can be applied.\n\nHowever, there are conditions under which the principle of force majeure might not be applicable:\n\n1. Pre-existing Conditions: If the event that caused the breach of contract was pre-existing, the principle of force majeure might not be applicable. For example, if a company was contracted to deliver goods to a client, but the goods were destroyed due to a pre-existing flood, the principle of force majeure might not be applicable.\n\n2. Lack of Notice: If the event that caused the breach of contract was unforeseen, but the parties had no notice of it, the principle of force majeure might not be applicable. For example, if a company was contracted to deliver goods to a client, but the goods were destroyed due to a hurricane, but the company had no notice of the hurricane, the principle of force majeure might not be applicable.\n\n3. Failure to Mitigate: If the parties failed to take reasonable steps to mitigate the damage caused by the unforeseen event, the principle of force majeure might not be applicable. For example, if a company was contracted to deliver goods to a client, but the goods were destroyed due to a hurricane, but the company failed to take reasonable steps to protect the goods, the principle of force majeure might not be applicable.\n\nIn conclusion, the principle of force majeure can be applied in cases where a breach of contract is due to unforeseeable events beyond the control of the parties. However, there are conditions under which the principle of force majeure might not be applicable. These conditions include pre-existing conditions, lack of notice, and failure to mitigate.<|im_end|>\n====================================================================================================\n<|im_start|>system\nYou are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\n<|im_start|>human\nIn the case where a defendant claims breach of contract due to unforeseeable events, how does the principle of 'force majeure' apply? For instance, if a company was unable to deliver contracted goods due to a natural disaster, provide a detailed explanation and outline any relevant conditions under which the force majeure principle might or might not be applicable.<|im_end|>\n<|im_start|>assistant\nThe principle of force majeure is a legal doctrine that excuses a breach of contract due to unforeseen events beyond the control of the parties involved. The term \"force majeure\" is French for \"greater force\" and refers to events that are beyond the control of the parties and are therefore beyond the scope of the contract.\n\nIn the case of a breach of contract due to unforeseeable events, the principle of force majeure can be applied in the following ways:\n\n1. Natural Disasters: If a natural disaster such as a hurricane, earthquake, flood, or wildfire occurs, the principle of force majeure can be applied. The event is beyond the control of the parties and is therefore beyond the scope of the contract. For example, if a company was contracted to deliver goods to a client, but the goods were destroyed in a hurricane, the principle of force majeure can be applied.\n\n2. War or Terrorism: If a war or terrorism occurs, the principle of force majeure can be applied. The event is beyond the control of the parties and is therefore beyond the scope of the contract. For example, if a company was contracted to deliver goods to a client, but the goods were destroyed in a bombing, the principle of force majeure can be applied.\n\n3. Public Health or Safety: If a public health or safety issue occurs, such as a pandemic or a major health crisis, the principle of force majeure can be applied. The event is beyond the control of the parties and is therefore beyond the scope of the contract. For example, if a company was contracted to deliver goods to a client, but the goods were destroyed due to a pandemic, the principle of force majeure can be applied.\n\n4. Governmental Actions: If a governmental action, such as a government shutdown or a change in laws, occurs, the principle of force majeure can be applied. The event is beyond the control of the parties and is therefore beyond the scope of the contract. For example, if a company was contracted to deliver goods to a client, but the goods were destroyed due to a government shutdown, the principle of force majeure can be applied.\n\nHowever, there are conditions under which the principle of force majeure might not be applicable:\n\n1. Pre-existing Conditions: If the event that caused the breach of contract was pre-existing, the principle of force majeure might not be applicable. For example, if a company was contracted to deliver goods to a client, but the goods were destroyed due to a pre-existing flood, the principle of force majeure might not be applicable.\n\n2. Lack of Notice: If the event that caused the breach of contract was unforeseen, but the parties had no notice of it, the principle of force majeure might not be applicable. For example, if a company was contracted to deliver goods to a client, but the goods were destroyed due to a hurricane, but the company had no notice of the hurricane, the principle of force majeure might not be applicable.\n\n3. Failure to Mitigate: If the parties failed to take reasonable steps to mitigate the damage caused by the unforeseen event, the principle of force majeure might not be applicable. For example, if a company was contracted to deliver goods to a client, but the goods were destroyed due to a hurricane, but the company failed to take reasonable steps to protect the goods, the principle of force majeure might not be applicable.\n\nIn conclusion, the principle of force majeure can be applied in cases where a breach of contract is due to unforeseeable events beyond the control of the parties. However, there are conditions under which the principle of force majeure might not be applicable. These conditions include pre-existing conditions, lack of notice, and failure to mitigate.<|im_end|>\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"prompt = \"Construct an argument in defense of a client accused of breaching intellectual property laws due to sharing copyrighted material in an educational setting. For example, a teacher shares portions of a textbook with students to support classroom discussion. Focus on any legal exceptions or defenses that may apply, such as the fair use doctrine in educational contexts.\"\npre_assistant(prompt)\nprint(100 * '=')\npost_assistant(prompt)","metadata":{"id":"BUPoJAmnTnCq","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T04:22:34.396515Z","iopub.execute_input":"2024-11-15T04:22:34.397216Z","iopub.status.idle":"2024-11-15T04:23:33.537587Z","shell.execute_reply.started":"2024-11-15T04:22:34.397165Z","shell.execute_reply":"2024-11-15T04:23:33.536645Z"}},"outputs":[{"name":"stdout","text":"<|im_start|>system\nYou are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\n<|im_start|>human\nConstruct an argument in defense of a client accused of breaching intellectual property laws due to sharing copyrighted material in an educational setting. For example, a teacher shares portions of a textbook with students to support classroom discussion. Focus on any legal exceptions or defenses that may apply, such as the fair use doctrine in educational contexts.<|im_end|>\n<|im_start|>assistant\nThe client is accused of breaching intellectual property laws by sharing copyrighted material in an educational setting. However, there are legal exceptions and defenses that may apply to this situation.\n\nFirstly, the fair use doctrine in educational contexts allows for the use of copyrighted material for purposes such as criticism, commentary, research, teaching, and parody. This doctrine is particularly relevant in educational settings where the primary intention is to educate and promote learning.\n\nSecondly, the concept of transformative use is also relevant. This means that the use of copyrighted material must be transformative, meaning it adds a new layer of meaning or value to the original work. For example, if a teacher shares portions of a textbook with students to support classroom discussion and the discussion is transformative, then the use of the copyrighted material may be considered fair.\n\nThirdly, the client may also argue that the use of copyrighted material is for the purpose of education and therefore qualifies as a defense under the doctrine of fair use.\n\nLastly, the client should also consider the concept of \"innocent infringement,\" which is a defense that may apply in certain circumstances. This defense is particularly relevant if the client did not intend to infringe on the intellectual property rights of the copyright holder.\n\nIn conclusion, while the client is accused of breaching intellectual property laws, there are legal exceptions and defenses that may apply to this situation. The fair use doctrine, transformative use, doctrine of fair use, innocent infringement, and the concept of educational context may all be relevant in determining the validity of the client's actions.<|im_end|>\n====================================================================================================\n<|im_start|>system\nYou are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\n<|im_start|>human\nConstruct an argument in defense of a client accused of breaching intellectual property laws due to sharing copyrighted material in an educational setting. For example, a teacher shares portions of a textbook with students to support classroom discussion. Focus on any legal exceptions or defenses that may apply, such as the fair use doctrine in educational contexts.<|im_end|>\n<|im_start|>assistant\nThe client is accused of breaching intellectual property laws by sharing copyrighted material in an educational setting. However, there are legal exceptions and defenses that may apply to this situation.\n\nFirstly, the fair use doctrine in educational contexts allows for the use of copyrighted material for purposes such as criticism, commentary, research, teaching, and parody. This doctrine is particularly relevant in educational settings where the primary intention is to educate and promote learning.\n\nSecondly, the concept of transformative use is also relevant. This means that the use of copyrighted material must be transformative, meaning it adds a new layer of meaning or value to the original work. For example, if a teacher shares portions of a textbook with students to support classroom discussion and the discussion is transformative, then the use of the copyrighted material may be considered fair.\n\nThirdly, the client may also argue that the use of copyrighted material is for the purpose of education and therefore qualifies as a defense under the doctrine of fair use.\n\nLastly, the client should also consider the concept of \"innocent infringement,\" which is a defense that may apply in certain circumstances. This defense is particularly relevant if the client did not intend to infringe on the intellectual property rights of the copyright holder.\n\nIn conclusion, while the client is accused of breaching intellectual property laws, there are legal exceptions and defenses that may apply to this situation. The fair use doctrine, transformative use, doctrine of fair use, innocent infringement, and the concept of educational context may all be relevant in determining the validity of the client's actions.<|im_end|>\n","output_type":"stream"}],"execution_count":53}]}